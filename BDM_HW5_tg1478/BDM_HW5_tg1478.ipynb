{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x11698fd50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SAT_FN = '/Users/tashaygreen/Downloads/SAT_Results.csv'\n",
    "HSD_FN = '/Users/tashaygreen/Downloads/DOE_High_School_Directory_2014-2015.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = spark.read \\\n",
    "            .format('com.databricks.spark.csv')\\\n",
    "            .option('header','true')\\\n",
    "            .option('inferSchema','true')\\\n",
    "            .option('parserLib','UNIVOCITY')\\\n",
    "            .load(HSD_FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are asked to compute the average SAT Math score of all high schools with 500 students or more, for\n",
    "each borough of the city. Meaning: what is the average SAT Math score of all high schools with 500 students\n",
    "or more in Manhattan, in Brooklyn, in Queens, in Bronx and in Staten Island.\n",
    "\n",
    "You must use Apache Spark for this lab. Both data sets must be loaded into RDDs, where all your\n",
    "manipulations must be applied on, though you are free to transform these RDDs into Sparkâ€™s DataFrame or\n",
    "SQL Context (though we have not covered this yet). The final result is expected to be a list of tuples borough\n",
    "names as the first elements, and the average scores as the second.\n",
    "\n",
    "Note 1: since the SAT Results also provide the number of test takers along with the average scores, you should\n",
    "use this information in computing the exact average scores above.\n",
    "Note 2: if a DBN in the SAT Results data set is not found in the High School Directory, you can safely ignore\n",
    "the test scores for that school."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'DBN'),\n",
       " (1, 'SCHOOL NAME'),\n",
       " (2, 'Num of SAT Test Takers'),\n",
       " (3, 'SAT Critical Reading Avg. Score'),\n",
       " (4, 'SAT Math Avg. Score'),\n",
       " (5, 'SAT Writing Avg. Score')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat = sc.textFile(SAT_FN, use_unicode=False).cache()\n",
    "list(enumerate(sat.first().split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('02M047', (6400, 16)),\n",
       " ('21K410', (207575, 475)),\n",
       " ('30Q301', (43120, 98)),\n",
       " ('17K382', (22066, 59))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extractScores(partId, list_of_records):\n",
    "    import csv\n",
    "    if partId==0:\n",
    "        list_of_records.next()\n",
    "    reader = csv.reader(list_of_records)\n",
    "    for row in reader:\n",
    "        if row[2]!='s':\n",
    "            (dbn, takers, score) = (row[0], int(row[2]), int(row[4]))\n",
    "            yield (dbn, (score*takers, takers))\n",
    "\n",
    "satScores = sat.mapPartitionsWithIndex(extractScores)\n",
    "satScores.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "schools = sc.textFile(HSD_FN, use_unicode=False).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('01M450', 'Manhattan'),\n",
       " ('01M539', 'Manhattan'),\n",
       " ('01M696', 'Manhattan'),\n",
       " ('02M374', 'Manhattan')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extractSchools(partId, list_of_records):\n",
    "    import csv\n",
    "    if partId==0:\n",
    "        list_of_records.next()\n",
    "    reader = csv.reader(list_of_records)\n",
    "    for row in reader:\n",
    "        if len(row)==58 and row[17].isdigit():\n",
    "            (dbn, boro, total_students) = (row[0], row[2], int(row[17]))\n",
    "            if total_students>500:\n",
    "                yield (dbn, boro)\n",
    "                \n",
    "largeSchools = schools.mapPartitionsWithIndex(extractSchools)\n",
    "largeSchools.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = largeSchools.join(satScores).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bronx', (23069, 59)),\n",
       " ('Staten Island', (52216, 107)),\n",
       " ('Bronx', (16317, 49)),\n",
       " ('Brooklyn', (33235, 85))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bronx', 470),\n",
       " ('Manhattan', 514),\n",
       " ('Brooklyn', 487),\n",
       " ('Staten Island', 477),\n",
       " ('Queens', 474)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.reduceByKey(lambda x,y: (x[0]+y[0], x[1]+y[1])) \\\n",
    "    .mapValues(lambda x: x[0]/x[1]) \\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to know how the Math scores vary across bus lines or subway lines serving the schools. Your\n",
    "task is to compute the average Math scores of all schools along each bus line and subway line. You can find the\n",
    "bus and subway lines serving each school in the High School Dictionary as bus and subway columns.\n",
    "\n",
    "The expected results are two lists:\n",
    "1. A list of key/value pairs: with bus line as keys, and the average Math scores as values.\n",
    "2. A list of key/value pairs: with subway line as keys, and the average Math scores as values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('01M292', ['B', 'D', 'F', 'J', 'M', 'Z']), ('01M448', ['F', 'J', 'M', 'Z'])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extractSubway(partId, list_of_records):\n",
    "    import csv\n",
    "    import operator\n",
    "    if partId==0:\n",
    "        list_of_records.next()\n",
    "    reader = csv.reader(list_of_records)\n",
    "    for row in reader:\n",
    "        if len(row)==58 and row[17].isdigit():\n",
    "            (dbn, subway) = (row[0],row[11])\n",
    "            #bus = bus.split(', ')\n",
    "            subway = reduce(operator.add, map(lambda x: x.split(' to ')[0].split(', '), subway.split('; ')))\n",
    "            yield (dbn, subway)\n",
    "            \n",
    "subway_avg = schools.mapPartitionsWithIndex(extractSubway)\n",
    "subway_avg.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('01M292', ['B39', 'M14A', 'M14D', 'M15', 'M15-SBS', 'M21', 'M22', 'M9']),\n",
       " ('01M448', ['M14A', 'M14D', 'M15', 'M21', 'M22', 'M9'])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extractBus(partId, list_of_records):\n",
    "    import csv\n",
    "    import operator\n",
    "    if partId==0:\n",
    "        list_of_records.next()\n",
    "    reader = csv.reader(list_of_records)\n",
    "    for row in reader:\n",
    "        if len(row)==58 and row[17].isdigit():\n",
    "            (dbn, bus) = (row[0],row[10])\n",
    "            bus = bus.split(', ')\n",
    "            #subway = reduce(operator.add, map(lambda x: x.split(' to ')[0].split(', '), subway.split('; ')))\n",
    "            yield (dbn, bus)\n",
    "            \n",
    "bus_avg = schools.mapPartitionsWithIndex(extractBus)\n",
    "bus_avg.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('S1115', 612),\n",
       " ('M79', 594),\n",
       " ('Q42', 582),\n",
       " ('M22', 574),\n",
       " ('Bx3', 571),\n",
       " ('B52', 560),\n",
       " ('B63', 557),\n",
       " ('B69', 548),\n",
       " ('B54', 543),\n",
       " ('B25', 541),\n",
       " ('M20', 540),\n",
       " ('M9', 539),\n",
       " ('M86', 538),\n",
       " ('B65', 538),\n",
       " ('B45', 534),\n",
       " ('Bx10', 534),\n",
       " ('Bx26', 533),\n",
       " ('B103', 531),\n",
       " ('Q64', 529),\n",
       " ('Bx22', 525),\n",
       " ('M72', 523),\n",
       " ('M5', 520),\n",
       " ('B41', 520),\n",
       " ('B38', 520),\n",
       " ('Q35', 519),\n",
       " ('M66', 518),\n",
       " ('B62', 513),\n",
       " ('Q88', 508),\n",
       " ('Q84', 507),\n",
       " ('Q30', 507),\n",
       " ('Q20A', 505),\n",
       " ('S79-SBS', 505),\n",
       " ('Q31', 504),\n",
       " ('B11', 503),\n",
       " ('M35', 496),\n",
       " ('M10', 495),\n",
       " ('Q17', 495),\n",
       " ('Q28', 492),\n",
       " ('Q13', 492),\n",
       " ('S57', 490),\n",
       " ('M31', 490),\n",
       " ('Bx28', 489),\n",
       " ('B9', 489),\n",
       " ('Q76', 488),\n",
       " ('S78', 486),\n",
       " ('S74', 486),\n",
       " ('S55', 486),\n",
       " ('S76', 486),\n",
       " ('B8', 485),\n",
       " ('M21', 485)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "bus_avg.join(satScores) \\\n",
    "          .flatMap(lambda x: itertools.product(x[1][0], [x[1][1]])) \\\n",
    "          .reduceByKey(lambda x, y: (x[0]+y[0], x[1]+y[1])) \\\n",
    "          .mapValues(lambda x: x[0]/x[1]) \\\n",
    "          .sortBy(lambda x: -x[1]) \\\n",
    "          .take(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('3', 513),\n",
       " ('A', 510),\n",
       " ('C', 510),\n",
       " ('R', 508),\n",
       " ('G', 503),\n",
       " ('D', 502),\n",
       " ('E', 501),\n",
       " ('1', 499),\n",
       " ('SIR', 498),\n",
       " ('4', 495),\n",
       " ('N', 493),\n",
       " ('B', 491),\n",
       " ('2', 488),\n",
       " ('Q', 482),\n",
       " ('N/A', 476),\n",
       " ('5', 461),\n",
       " ('7', 457),\n",
       " ('M', 454),\n",
       " ('F', 445),\n",
       " ('J', 439),\n",
       " ('Z', 438),\n",
       " ('6', 432),\n",
       " ('S', 427),\n",
       " ('L', 426)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subway_avg.join(satScores) \\\n",
    "          .flatMap(lambda x: itertools.product(x[1][0], [x[1][1]])) \\\n",
    "          .reduceByKey(lambda x, y: (x[0]+y[0], x[1]+y[1])) \\\n",
    "          .mapValues(lambda x: x[0]/x[1]) \\\n",
    "          .sortBy(lambda x: -x[1]) \\\n",
    "          .take(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [ipykernel_py2]",
   "language": "python",
   "name": "Python [ipykernel_py2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
